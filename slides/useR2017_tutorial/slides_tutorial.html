<!DOCTYPE html>
<html>
  <head>
    <title>OpenML: Connecting R to the Machine Learning Platform OpenML</title>
    <meta charset="utf-8">
    <meta name="author" content="Joaquin Vanschoren, Bernd Bischl, Heidi Seibold" />
    <link href="libs/remark-css/example.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# OpenML: Connecting R to the Machine Learning Platform OpenML
## useR! 2017 tutorial
### Joaquin Vanschoren, Bernd Bischl, Heidi Seibold
### <ul>
<li><em>If you haven’t done so yet, create an account on OpenML.org.</em></li>
<li><em>If you haven’t done so yet, install the OpenML R package and one of the packages farff or RWeka</em></li>
</ul>

---

&lt;!-- For this to work, install xaringan (devtools::install_github('yihui/xaringan')) --&gt;



- If you haven't done so yet, create an account on [OpenML.org](www.openml.org).

- If you haven't done so yet, install the OpenML R package and one of the packages farff or RWeka:

```r
install.packages("OpenML")
install.packages("farff")  # or install.packages("RWeka")
```

```r
library("OpenML")
```




- If something is not clear / you have a question / you have a problem, please **let us know**!

- We will have lots of practicals, if you are faster than others, you can 
check out https://www.openml.org/guide or help others.



---
Help
![](slides_tutorial_files/openml-cheatsheet.jpg)

---
## OpenML useR! Tutorial

Learning goals:

- Understand the **potentials** of OpenML

- Use the OpenML **online platform** and the **R package**
  + Creating, uploading and downloading 
  + Running algorithms on OpenML tasks
  
- Know about cool OpenML **projects** and how to **get involved**



---
## Intro to openml.org 
&lt;!-- [15 minutes, Joaquin] --&gt;

&gt; Resources:  
&gt; [NIPS slides](https://github.com/openml/articles/blob/master/OpenML%20NIPS.pdf)

- Why, what, how, who, for whom
- Data sets, tasks, flows, runs (all have their own website)
- vocabulary: features = covariates, number of observations = number of instances, ML = Machine Learing (not maximum likelihood)



---
## Intro to the OpenML R package
&gt; Resources:  
&gt; [Paper](https://bitbucket.org/giuseppec/openml-r-paper/src)  
&gt; [Tutorial](http://openml.github.io/openml-r/vignettes/OpenML.html)  
&gt; [Reisensburg talk](https://bitbucket.org/giuseppec/openml-r-paper/src)  
&gt; [Heidi's departement presentation](https://github.com/openml/articles/tree/master/slides/heidi_hittisau)  
&gt; [mlr loves OpenML blogpost](http://mlr-org.github.io/mlr-loves-OpenML/)



---
### Motivating example: A small benchmarking study demo 
&lt;!-- [5 minutes, Joaquin] --&gt;

- What we want to do today: How to run a simple benchmark study
- E.g. Gesture phase recognition (https://www.openml.org/d/4537)
- Try to join if you (already) can
- Link to batchmark blogpost [TODO?]


```r
library("OpenML")
library("mlr")

# Download a machine learning task from OpenML
task = getOMLTask(task.id = 146567L)
# Build any classifier with mlr
lrn = makeLearner("classif.rpart")
# Run the learner on the task
run.mlr = runTaskMlr(task, lrn)
# Upload and tag
run.id = uploadOMLRun(run.mlr, tags = "useR17")
```

---
### Installation and configuration 
&lt;!-- [3 minutes, Joaquin] --&gt;

You need OpenML and an ARFF reader


```r
# install.packages(c("OpenML","farff"))
library("OpenML")
```

---
You also need an OpenML API key to talk to the server


```r
#setOMLConfig(apikey = "c1994bdb7ecb3c6f3c8f3b35f4b47f1f")
```

- Find your own key in your OpenML profile

![](slides_tutorial_files/screenshot_apikey.png) 
---
Permanently save your API disk to you config file (~/.openml/config)


```r
#saveOMLConfig(apikey = "c1994bdb7ecb3c6f3c8f3b35f4b47f1f", overwrite=TRUE)
```

Other options:
- 'server': default http://www.openml.org/api/v1
- 'cachedir': cache directory
- 'verbosity': 0 (normal) - 2 (debug)
- 'arff.reader': 'farff' (default) or 'RWeka'
- 'confirm.upload': default FALSE


```r
getOMLConfig()
```

```
## OpenML configuration:
##   server           : https://www.openml.org/api/v1
##   cachedir         : /Users/joa/.openml/cache
##   verbosity        : 1
##   arff.reader      : farff
##   confirm.upload   : FALSE
##   apikey           : ***************************0acb1
```

---
class:inverse

### *Practical*  
&lt;!-- [5 minutes, Jouaqin] --&gt;

- Install the OpenML R package (if you haven't done so yet)
- Add your API-key to your config file
- Configure OpenML to your liking

---
### Listing 
&lt;!-- [7 minutes, Jouaqin] --&gt;
Listing datasets
- First time can take a short while, cached aftrwards

```r
datasets = listOMLDataSets()  # returns active data sets
datasets[1:20, c("data.id", "name", "number.of.instances", "number.of.features")]
```

```
##    data.id                name number.of.instances number.of.features
## 1        1              anneal                 898                 39
## 2        2              anneal                 898                 39
## 3        3            kr-vs-kp                3196                 37
## 4        4               labor                  57                 17
## 5        5          arrhythmia                 452                280
## 6        6              letter               20000                 17
## 7        7           audiology                 226                 70
## 8        8     liver-disorders                 345                  7
## 9        9               autos                 205                 26
## 10      10               lymph                 148                 19
## 11      11       balance-scale                 625                  5
## 12      12       mfeat-factors                2000                217
## 13      13       breast-cancer                 286                 10
## 14      14       mfeat-fourier                2000                 77
## 15      15            breast-w                 699                 10
## 16      16      mfeat-karhunen                2000                 65
## 17      18 mfeat-morphological                2000                  7
## 18      20         mfeat-pixel                2000                241
## 19      21                 car                1728                  7
## 20      22       mfeat-zernike                2000                 48
```

- Find datasets by name

```r
subset(datasets, name == "eeg-eye-state")
```

```
##      data.id          name version status format
## 1177    1471 eeg-eye-state       1 active   ARFF
##                             tags majority.class.size
## 1177 study_14, study_34, study_7                8257
##      max.nominal.att.distinct.values minority.class.size number.of.classes
## 1177                              -1                6723                 2
##      number.of.features number.of.instances
## 1177                 15               14980
##      number.of.instances.with.missing.values number.of.missing.values
## 1177                                       0                        0
##      number.of.numeric.features number.of.symbolic.features
## 1177                         14                           1
```
---
Idem:
- List tasks

```r
tasks = listOMLTasks()
eeg_tasks = listOMLTasks(data.name = "eeg-eye-state")
```

Includes:
- task.id
- task.type (e.g. classification)
- all data properties
- target.feature
- estimation.procedure (e.g. 10-fold CV)
- evaluation.measure (e.g. AUROC)

---
Likewise:
- List flows

```r
flows = listOMLFlows()
```
---
Runs and evaluations need at least a task.id, flow.id, run.id, uploader.id, tag
- List runs

```r
runs = listOMLRuns(task.id = 146567L)
```
- List evaluations

```r
runs = listOMLRunEvaluations(task.id = 146567L)
```

---
class:inverse

### *Practical*  
&lt;!-- [5 minutes, Joaquin] --&gt;
- Get and study the full list of returned dataset characteristics
- List all datasets with more that 100000 observations and fewer than 5 features
- List all regression tasks corresponding to data sets with between 
  50 and 55 observations.
- Find the data.id for dataset 'GesturePhaseSegmentationRAW'
- List all area_under_roc_curve evaluations for task 146567
---

### Downloading 
&lt;!-- [10 minutes, Joaquin] --&gt;
Download dataset:

```r
gesture.data = getOMLDataSet(data.id = 4537L)
head(gesture.data$data)
```

```
##        lhx      lhy      lhz      rhx      rhy      rhz       hx       hy
## 0 5.347435 4.363681 1.501913 5.258967 4.319263 1.488703 5.037871 1.618295
## 1 4.869622 4.254210 1.556133 5.240113 4.346338 1.554309 5.037610 1.618370
## 2 5.357447 4.364039 1.500969 5.238928 4.347924 1.554150 5.037514 1.618298
## 3 4.942886 4.281878 1.546513 5.111436 4.229660 1.527091 5.037526 1.618612
## 4 5.003160 4.278530 1.542866 4.985812 4.182155 1.520330 5.037557 1.619226
## 5 5.064488 4.290401 1.542146 4.955739 4.163175 1.511876 5.037724 1.618397
##         hz       sx       sy       sz      lwx      lwy      lwz      rwx
## 0 1.778350 5.062803 4.229656 1.772577 4.972902 4.301065 1.564781 5.553945
## 1 1.778573 5.061430 4.228504 1.772859 4.974908 4.303656 1.565527 5.423875
## 2 1.778774 5.059245 4.228004 1.773568 4.981612 4.305363 1.563643 5.332170
## 3 1.778855 5.056475 4.226891 1.774519 4.987158 4.304063 1.565929 5.311104
## 4 1.778925 5.052367 4.225485 1.775536 4.983912 4.296833 1.569889 5.193762
## 5 1.779722 5.045395 4.223284 1.777401 5.000410 4.301358 1.566544 5.164159
##        rwy      rwz timestamp phase
## 0 4.370456 1.553521   5702026  Rest
## 1 4.303708 1.569942   5702058  Rest
## 2 4.438061 1.572841   5702089  Rest
## 3 4.396774 1.566368   5702120  Rest
## 4 4.335417 1.560144   5702167  Rest
## 5 4.313107 1.552097   5702307  Rest
```

---
- Download tasks (remember?)

```r
task = getOMLTask(task.id = 146567L)
task
```

```
## 
## OpenML Task 146567 :: (Data ID = 4537)
##   Task Type            : Supervised Classification
##   Data Set             : GesturePhaseSegmentationRAW :: (Version = 1, OpenML ID = 4537)
##   Target Feature(s)    : phase
##   Estimation Procedure : Stratified crossvalidation (1 x 10 folds)
##   Evaluation Measure(s): predictive_accuracy
```

---
- Likewise:

```r
flow = getOMLFlow(flow.id = 100L)
flow
```

```
## 
## Flow "weka.J48" :: (Version = 2, Flow ID = 100)
## 	External Version         : Weka_3.7.5_9117
## 	Dependencies             : Weka_3.7.5
## 	Number of Flow Parameters: 12
## 	Number of Flow Components: 0
```

```r
run = getOMLRun(run.id = 3893285L)
run
```

```
## 
## OpenML Run 3893285 :: (Task ID = 146567, Flow ID = 6770)
## 	User ID  : 2
## 	Tags     : useR17
## 	Learner  : mlr.classif.randomForest(30)
## 	Task type: Supervised Classification
```

---
class:inverse

### *Practical*  
&lt;!-- [5 minutes, Joaquin] --&gt;

- Download task with task ID 146567.
- Extract the dataset from this task
- List and get the current runs with tag 'useR17'

---
class: inverse
&lt;!-- background-image: url(https://c1.staticflickr.com/5/4049/4468213356_07ffffd287_z.jpg) --&gt;
background-image: url(slides_tutorial_files/cat.jpg)
background-size: cover

# BREAK TIME

???
Image credit: [Dave Dugdale](https://flic.kr/p/7NQLaj)

---

## Intro to mlr 
&lt;!-- [15 minutes, Bernd] --&gt;

mlr = standardized interface for machine learning algorithms in R

![](slides_tutorial_files/mlr.jpg) 

`\(\rightarrow\)` exactly what is needed for OpenML!

???
Image can be changed here if needed:
https://docs.google.com/drawings/d/1DRWxUC-fmxM-wzLZeihXcjieu1A6UKnaKj6D5lNDphA/edit?usp=sharing



---
### Running and uploading 
&lt;!-- [10 minutes, Bernd] --&gt;

Create a run:

1. Define a learner using the `mlr` package
2. Apply to a task using `runTaskMlr()`


```r
# create a randomForest learner
lrn = makeLearner("classif.randomForest", mtry = 2)
# download a task
task = getOMLTask(task.id = 37)
# create the run
run.mlr = runTaskMlr(task, lrn)
```


---
### Running and uploading

```r
run.mlr
```

```
## $run
## 
## OpenML Run NA :: (Task ID = 37, Flow ID = NA)
## 
## $bmr
##    task.id           learner.id acc.test.join timetrain.test.sum
## 1 diabetes classif.randomForest     0.7708333              7.835
##   timepredict.test.sum
## 1                0.322
## 
## $flow
## 
## Flow "mlr.classif.randomForest" :: (Version = NA, Flow ID = NA)
## 	External Version         : R_3.3.2-v2.b88a2294
## 	Dependencies             : R_3.3.2, OpenML_1.3, mlr_2.11, randomForest_4.6.12
## 	Number of Flow Parameters: 20
## 	Number of Flow Components: 0
## 
## attr(,"class")
## [1] "OMLMlrRun"
```


&lt;!-- From a didactical standpoint I would not include this: --&gt;
&lt;!-- 
- Extract the `BenchmarkResult` object via


```r
convertOMLMlrRunToBMR(run.mlr)
```

```
##    task.id           learner.id acc.test.join timetrain.test.sum
## 1 diabetes classif.randomForest     0.7708333              7.835
##   timepredict.test.sum
## 1                0.322
```
--&gt;


&lt;!--
- The `run.mlr` object contains three slots
  - `run`: contains the information of the run, i.e., the hyperparameter values and the learner predictions.
  - `bmr`: the `BenchmarkResult` object containing the results of the learner that is applied on the task.
  - `flow`: contains information about the algorithm.
--&gt;
---
### Running and uploading 

Upload run to OpenML server:

```r
run.id = uploadOMLRun(run.mlr)
```


```r
run.id
```

```
## [1] 3828647
```

- The server assigns a `run.id` which can be used to

  - download the run: `getOMLRun(run.id)`, or
  - look up the run online on https://www.openml.org/r/3828647.
  
- The server automatically computes evaluation measures     
`\(\rightarrow\)`https://www.openml.org/r/3828647.

&lt;!-- - It is also possible to upload runs with specific tags using the `tags` argument, so that finding the run with a specific tag becomes easier. --&gt;

---
class:inverse
### *Practical*  
&lt;!-- [25 minutes, Bernd] --&gt;

&lt;!-- TODO: exchange XXX with the task number --&gt;
- Run your favorite learner/algorithm (from mlr) on task XXX that you already downloaded.
Hint: use `listLearners()` to find appropriate learners for that task.

- Upload your run to OpenML. Add the tag "useR17". Hint: 

```r
run.id = uploadOMLRun(myrun, tag = "useR17")
```

- Check if the upload worked by going to the website. Check if the tag was
  added (you can still add it on the website if you forgot during the upload). 
  
- Check the predictive performance of the run 
(it may take a while before the server has calculated the performance measures `\(\rightarrow\)` give it some time).
  
---
class:inverse
### *Solution*  

- Run your favorite learner/algorithm (from mlr) on task XXX that you already downloaded.


```r
# select the learner manually from lrn.list
all.lrns = listLearners()
# run favorite learner
lrn = makeLearner("classif.rpart")
myrun = runTaskMlr(task, lrn)
```

- Upload your run to OpenML. Add the tag "useR17". 


```r
myrun.id = uploadOMLRun(myrun, tags = "useR17")
```



---
class:inverse
### *Solution*  

- Check if the upload worked by going to the website. Also check if the tag was
  added (you can also still add it on the website). 
  
Use the value from `myrun.id` and go to https://www.openml.org/r/3829199.

- Check the predictive performance of the run by looking at several evaluation measures.

   - Go to https://www.openml.org/r/3829199 
   - Scroll down to *Evaluation measures*. 

You can also get the results via

```r
listOMLRunEvaluations(run.id = myrun.id)
```


---
## Tags
&lt;!-- [10 minutes, Heidi] --&gt;
Use tags to sort and find data, tasks, flows and runs.

![](slides_tutorial_files/Screenshot_tags.png) 




```r
uploadOMLRun(myrun, tags = c("tag1", "tag2"))
```

---
## Studies
Studies are an extension of tags and get their own website.   
Tag must be `study_XX`

![](slides_tutorial_files/Screenshot_study.png)

???
- With tasks we can e.g. combine several runs and find them again and make 
a little benchmarking study.
- The information what the tag means probably not obvious to other OpenML users:
this is why we created studies
- Study = tag + website with study information



---
## Studies

![](slides_tutorial_files/Screenshot_study2.png)

```r
uploadOMLRun(myrun, tags = "study_30")
```


---
## Evaluations

```r
evals = listOMLRunEvaluations(tag = "study_30")
evals[1:3, c("data.name", "learner.name", "predictive.accuracy")]
```

```
##   data.name         learner.name predictive.accuracy
## 1  diabetes classif.randomForest            0.772135
## 2     sonar classif.randomForest            0.817308
## 3  haberman classif.randomForest            0.748366
```

![](slides_tutorial_files/figure-html/unnamed-chunk-32-1.png)&lt;!-- --&gt;


---
class:inverse

### *Practical*  
&lt;!-- [10 minutes, Heidi] --&gt;

- List the names of all data sets in study_27 
- Summarize the performance results of study_27 (look at predictive accuracy)

&gt; Predictive accuracy is the percentage of instances that are classified correctly.   
&gt; (Information like this can be found on [openml.org/a](https://www.openml.org/a))

- Bonus questions for fast solvers: 
  + What are the two different versions of ksvm?
  + What do the different setup.id s mean?

---
class:inverse

### *Solution*  
&lt;!-- [10 minutes, Heidi] --&gt;

- List the names of all data sets in study_27
- Summarize the performance results of study_27


```r
*evals = listOMLRunEvaluations(tag = "study_27")
evals$setup.id = as.factor(evals$setup.id)

library("ggplot2")
ggplot(evals, aes(x = setup.id, y = predictive.accuracy, 
                  color = data.name, group = data.name)) + 
  geom_point() + geom_line() + 
  facet_grid(~ flow.name, scales = "free")
```

![](slides_tutorial_files/figure-html/unnamed-chunk-33-1.png)&lt;!-- --&gt;

---
class:inverse
Why are there two different versions of the flow?

```r
fids = unique(evals$flow.id)
flws = lapply(fids, getOMLFlow)
flws
```

```
## [[1]]
## 
## Flow "mlr.classif.ksvm" :: (Version = 4, Flow ID = 4704)
## 	External Version         : R_3.3.1-v2.bf0ac616
## 	Dependencies             : R_3.3.1, OpenML_1.0, mlr_2.9, kernlab_0.9.24
## 	Number of Flow Parameters: 19
## 	Number of Flow Components: 0
## 
## [[2]]
## 
## Flow "mlr.classif.ksvm" :: (Version = 5, Flow ID = 4705)
## 	External Version         : R_3.2.2-v2.f878bda4
## 	Dependencies             : R_3.2.2, OpenML_1.0, mlr_2.10, kernlab_0.9.24
## 	Number of Flow Parameters: 19
## 	Number of Flow Components: 0
```

---
class:inverse
What are the different setup IDs?

```r
rids = evals$run.id
runs = lapply(rids, getOMLRun)
params = lapply(runs, getOMLRunParList)
params[[1]]
```

```
## This is a 'OMLRunParList' with the following parameters:
##    name value component
## 1:  fit FALSE        NA
```

```r
params[[5]]
```

```
## This is a 'OMLRunParList' with the following parameters:
##    name   value component
## 1: type kbb-svc        NA
## 2:  fit   FALSE        NA
```

```r
params[[19]]
```

```
## This is a 'OMLRunParList' with the following parameters:
##    name    value component
## 1: type spoc-svc        NA
## 2:  fit    FALSE        NA
```
The difference seems to be the type.

---
class:inverse
Let's add the type info to the evals data frame.

```r
evals$type = sapply(params, 
                     function(x) ifelse(is.null(x$type$value), 
                                        NA, x$type$value))
evals$type
```

```
##  [1] NA         NA         NA         "kbb-svc"  "kbb-svc"  "kbb-svc" 
##  [7] "spoc-svc" "spoc-svc" "spoc-svc" NA         NA         NA        
## [13] NA         "kbb-svc"  "kbb-svc"  "kbb-svc"  "spoc-svc" "spoc-svc"
## [19] "spoc-svc"
```

```r
evals$type[is.na(evals$type)] = getDefaults( 
  getParamSet( 
*  convertOMLFlowToMlr(flws[[1]])
  ) 
)$type

evals$type
```

```
##  [1] "C-svc"    "C-svc"    "C-svc"    "kbb-svc"  "kbb-svc"  "kbb-svc" 
##  [7] "spoc-svc" "spoc-svc" "spoc-svc" "C-svc"    "C-svc"    "C-svc"   
## [13] "C-svc"    "kbb-svc"  "kbb-svc"  "kbb-svc"  "spoc-svc" "spoc-svc"
## [19] "spoc-svc"
```

---
class:inverse
Now we can make a more understandable plot.

```r
ggplot(evals, aes(x = type, y = predictive.accuracy, 
                  color = data.name, group = data.name)) + 
  geom_point() + geom_line() + 
  facet_grid(~ flow.name, scales = "free")
```

![](slides_tutorial_files/figure-html/unnamed-chunk-37-1.png)&lt;!-- --&gt;



---
background-image: url(slides_tutorial_files/cool_stuff_text.png)
background-size: 70% auto
## Cool stuff people are already doing with OpenML
&lt;!-- [15 minutes, Heidi] --&gt;

???
Image-credit: https://commons.wikimedia.org

---
### OpenML Bot 
- Currently completing 100.000+ runs per day on Azure
- Exploring hyperparameters of xgboost,  ranger, and other popular machine learning algorithms
- Using 75 datasets from study_14

![](slides_tutorial_files/robot_profil.PNG)

---
### OpenML meta learning: Making defaults great again!
- Choose between different performance measures (AUC, RMSE, ...)
- Predict the pareto front for this measure and the training time
- E. g. for xgboost: Prediction for hyperparameters on a new dataset, which will outperform the defaults

![](slides_tutorial_files/xgboost_pareto_front.png)

---
### OpenML in drug discovery
Predict which drugs will inhibit certain proteins   
(and hence viruses, parasites, ...)

![](slides_tutorial_files/qsar.jpg)
&lt;!-- &lt;img src="slides_tutorial_files/qsar.pdf" width="4200" height="4200"&gt; --&gt;
&lt;!-- &lt;object data="slides_tutorial_files/qsar.pdf" type="application/pdf" width="700px" height="700px"&gt; --&gt;
    &lt;!-- &lt;embed src="slides_tutorial_files/qsar.pdf"&gt; --&gt;
    &lt;!--     This browser does not support PDFs. Please download the PDF to view it: &lt;a href="slides_tutorial_files/qsar.pdf"&gt;Download PDF&lt;/a&gt;.&lt;/p&gt; --&gt;
    &lt;!-- &lt;/embed&gt; --&gt;
&lt;!-- &lt;/object&gt; --&gt;

---
class: inverse
&lt;!-- background-image: url(https://c1.staticflickr.com/6/5477/14101220086_a633ec9674_c.jpg) --&gt;
background-image: url(slides_tutorial_files/fish.jpg)
background-size: cover

# Contributors needed! https://github.com/openml/OpenML/wiki/How-to-contribute
&lt;!-- [10 minutes, Heidi] --&gt;


???
Image credit: [Papahānaumokuākea Marine National Monument](https://flic.kr/p/neCvxt)

---
class: inverse, center, middle
![](slides_tutorial_files/OpenML_heart_OS.png)

Thanks to all the great folks who have been contributing    
to OpenML and the R package.
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
